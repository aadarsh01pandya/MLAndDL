{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#face registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition as fr\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#live image capturing\n",
    "\n",
    "# import cv2\n",
    "# import face_recognition as fr\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "#we are making the data frame on saving the image detail becous image jo hoga who list ka form ma aaya ga 1D array\n",
    "fname='feature.csv'\n",
    "try:\n",
    "    df=pd.read_csv(fname)\n",
    "except:\n",
    "    df=pd.DataFrame({'name':[],'enc':[]})\n",
    "\n",
    "\n",
    "counter =0\n",
    "names=[]\n",
    "feats=[]\n",
    "name=input('Enter the name: ')\n",
    "\n",
    "\n",
    "fd=cv2.CascadeClassifier(cv2.data.haarcascades+ 'haarcascade_frontalface_default.xml')\n",
    "vid=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ack,img=vid.read()\n",
    "    if ack:\n",
    "        #do the entire processing\n",
    "        faces=fd.detectMultiScale(img,1.2,2,minSize=(150,150))\n",
    "        #faces= [(x,y,w,h),(x2,y2,w2,h2)]\n",
    "\n",
    "        if len(faces)==1:\n",
    "            x,y,w,h=faces[0]\n",
    "            faces_img=img[y:y+h,x:x+w,:].copy()\n",
    "            face_enc=fr.face_encodings(faces_img)\n",
    "\n",
    "            if len(face_enc)==1:\n",
    "                counter+=1\n",
    "                names+=[name]\n",
    "                feats+=[face_enc[0].tolist()]\n",
    "\n",
    "            if counter==20:\n",
    "                f=pd.DataFrame({'name':names, 'enc':feats})  \n",
    "                df=pd.concat([df,f],axis=0,ignore_index=True)  \n",
    "                df.to_csv(fname)\n",
    "                break\n",
    "\n",
    "\n",
    "        cv2.imshow('preview',img)  #depends on requirement\n",
    "        key=cv2.waitKey(1)\n",
    "        if key==ord('x'):\n",
    "            break\n",
    "cv2.destroyAllWindows();  cv2.waitKey(1)\n",
    "vid.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#face recogination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#live image capturing\n",
    "\n",
    "# import cv2\n",
    "# import face_recognition as fr\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "#we are making the data frame on saving the image detail becous image jo hoga who list ka form ma aaya ga 1D array\n",
    "fname='feature.csv'\n",
    "\n",
    "try:\n",
    "    df=pd.read_csv(fname)\n",
    "except:\n",
    "    print('Face Data is not found')\n",
    "else:\n",
    "\n",
    "\n",
    "\n",
    "    fd=cv2.CascadeClassifier(cv2.data.haarcascades+ 'haarcascade_frontalface_default.xml')\n",
    "    vid=cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        ack,img=vid.read()\n",
    "        if ack:\n",
    "            #do the entire processing\n",
    "            faces=fd.detectMultiScale(img,1.2,2,minSize=(150,150))\n",
    "            #faces= [(x,y,w,h),(x2,y2,w2,h2)]\n",
    "\n",
    "            if len(faces)==1:\n",
    "                x,y,w,h=faces[0]\n",
    "                faces_img=img[y:y+h,x:x+w,:].copy()\n",
    "                face_enc=fr.face_encodings(faces_img)\n",
    "\n",
    "                if len(face_enc)==1:\n",
    "                    feats_data=df['enc'].apply(lambda x:eval(x)).values.tolist()\n",
    "\n",
    "                    matches=fr.compare_faces(face_enc, np.array(feats_data))\n",
    "                    if True in matches:\n",
    "                        match_ind=matches.index(True)\n",
    "                        name=df['name'][match_ind]\n",
    "                    else:\n",
    "                        name='UnKnown'   \n",
    "                    cv2.putText(img,name,(150,150)  ,   \n",
    "                        cv2.FONT_HERSHEY_PLAIN,10,(0,0,255),5)\n",
    "\n",
    "\n",
    "\n",
    "            cv2.imshow('preview',img)  #depends on requirement\n",
    "            key=cv2.waitKey(1)\n",
    "            if key==ord('x'):\n",
    "                break\n",
    "cv2.destroyAllWindows();  cv2.waitKey(1)\n",
    "vid.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
